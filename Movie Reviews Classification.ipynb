{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5de75b46",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2bcad231",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize,sent_tokenize\n",
    "import matplotlib.pyplot as plt\n",
    "# import torch\n",
    "# from torch import nn\n",
    "# from transformers import BertModel\n",
    "# from torch.optim import Adam\n",
    "# from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6340874b",
   "metadata": {},
   "source": [
    "# Data Reading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5f7ca84a",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv(\"IMDB Dataset.csv\", sep=',')\n",
    "# dataset = pd.read_csv(\"fruits.csv\", sep=',')\n",
    "# display(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03324c96",
   "metadata": {},
   "source": [
    "# Text Pre-processing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a130a92",
   "metadata": {},
   "source": [
    "### Remove punctuation & lowercase all characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "aebb2d04",
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "string.punctuation\n",
    "\n",
    "def remove_punctuation(text):\n",
    "    return \"\".join([i.lower() for i in text if i not in string.punctuation])\n",
    "\n",
    "# storing the puntuation free and lowercased text\n",
    "dataset['free_punc_review']= dataset['review'].apply(lambda x:remove_punctuation(x))\n",
    "\n",
    "# display(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd0cbc84",
   "metadata": {},
   "source": [
    "### Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1fe413d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "def tokenization(text):\n",
    "    tokens = word_tokenize(text)\n",
    "    return tokens\n",
    "dataset['review_tokenied'] = dataset['free_punc_review'].apply(lambda x: tokenization(x))\n",
    "\n",
    "# display(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d823c240",
   "metadata": {},
   "source": [
    "### Remove stop words and lemmatize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "16c4f5b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>free_punc_review</th>\n",
       "      <th>review_tokenied</th>\n",
       "      <th>lemmatized_no_stopwords</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>One of the other reviewers has mentioned that ...</td>\n",
       "      <td>positive</td>\n",
       "      <td>one of the other reviewers has mentioned that ...</td>\n",
       "      <td>[one, of, the, other, reviewers, has, mentione...</td>\n",
       "      <td>[one, reviewer, mentioned, watching, 1, oz, ep...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A wonderful little production. &lt;br /&gt;&lt;br /&gt;The...</td>\n",
       "      <td>positive</td>\n",
       "      <td>a wonderful little production br br the filmin...</td>\n",
       "      <td>[a, wonderful, little, production, br, br, the...</td>\n",
       "      <td>[wonderful, little, production, br, br, filmin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I thought this was a wonderful way to spend ti...</td>\n",
       "      <td>positive</td>\n",
       "      <td>i thought this was a wonderful way to spend ti...</td>\n",
       "      <td>[i, thought, this, was, a, wonderful, way, to,...</td>\n",
       "      <td>[thought, wonderful, way, spend, time, hot, su...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Basically there's a family where a little boy ...</td>\n",
       "      <td>negative</td>\n",
       "      <td>basically theres a family where a little boy j...</td>\n",
       "      <td>[basically, theres, a, family, where, a, littl...</td>\n",
       "      <td>[basically, there, family, little, boy, jake, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Petter Mattei's \"Love in the Time of Money\" is...</td>\n",
       "      <td>positive</td>\n",
       "      <td>petter matteis love in the time of money is a ...</td>\n",
       "      <td>[petter, matteis, love, in, the, time, of, mon...</td>\n",
       "      <td>[petter, matteis, love, time, money, visually,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49995</th>\n",
       "      <td>I thought this movie did a down right good job...</td>\n",
       "      <td>positive</td>\n",
       "      <td>i thought this movie did a down right good job...</td>\n",
       "      <td>[i, thought, this, movie, did, a, down, right,...</td>\n",
       "      <td>[thought, movie, right, good, job, wasnt, crea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49996</th>\n",
       "      <td>Bad plot, bad dialogue, bad acting, idiotic di...</td>\n",
       "      <td>negative</td>\n",
       "      <td>bad plot bad dialogue bad acting idiotic direc...</td>\n",
       "      <td>[bad, plot, bad, dialogue, bad, acting, idioti...</td>\n",
       "      <td>[bad, plot, bad, dialogue, bad, acting, idioti...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49997</th>\n",
       "      <td>I am a Catholic taught in parochial elementary...</td>\n",
       "      <td>negative</td>\n",
       "      <td>i am a catholic taught in parochial elementary...</td>\n",
       "      <td>[i, am, a, catholic, taught, in, parochial, el...</td>\n",
       "      <td>[catholic, taught, parochial, elementary, scho...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49998</th>\n",
       "      <td>I'm going to have to disagree with the previou...</td>\n",
       "      <td>negative</td>\n",
       "      <td>im going to have to disagree with the previous...</td>\n",
       "      <td>[im, going, to, have, to, disagree, with, the,...</td>\n",
       "      <td>[im, going, disagree, previous, comment, side,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49999</th>\n",
       "      <td>No one expects the Star Trek movies to be high...</td>\n",
       "      <td>negative</td>\n",
       "      <td>no one expects the star trek movies to be high...</td>\n",
       "      <td>[no, one, expects, the, star, trek, movies, to...</td>\n",
       "      <td>[one, expects, star, trek, movie, high, art, f...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>50000 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  review sentiment  \\\n",
       "0      One of the other reviewers has mentioned that ...  positive   \n",
       "1      A wonderful little production. <br /><br />The...  positive   \n",
       "2      I thought this was a wonderful way to spend ti...  positive   \n",
       "3      Basically there's a family where a little boy ...  negative   \n",
       "4      Petter Mattei's \"Love in the Time of Money\" is...  positive   \n",
       "...                                                  ...       ...   \n",
       "49995  I thought this movie did a down right good job...  positive   \n",
       "49996  Bad plot, bad dialogue, bad acting, idiotic di...  negative   \n",
       "49997  I am a Catholic taught in parochial elementary...  negative   \n",
       "49998  I'm going to have to disagree with the previou...  negative   \n",
       "49999  No one expects the Star Trek movies to be high...  negative   \n",
       "\n",
       "                                        free_punc_review  \\\n",
       "0      one of the other reviewers has mentioned that ...   \n",
       "1      a wonderful little production br br the filmin...   \n",
       "2      i thought this was a wonderful way to spend ti...   \n",
       "3      basically theres a family where a little boy j...   \n",
       "4      petter matteis love in the time of money is a ...   \n",
       "...                                                  ...   \n",
       "49995  i thought this movie did a down right good job...   \n",
       "49996  bad plot bad dialogue bad acting idiotic direc...   \n",
       "49997  i am a catholic taught in parochial elementary...   \n",
       "49998  im going to have to disagree with the previous...   \n",
       "49999  no one expects the star trek movies to be high...   \n",
       "\n",
       "                                         review_tokenied  \\\n",
       "0      [one, of, the, other, reviewers, has, mentione...   \n",
       "1      [a, wonderful, little, production, br, br, the...   \n",
       "2      [i, thought, this, was, a, wonderful, way, to,...   \n",
       "3      [basically, theres, a, family, where, a, littl...   \n",
       "4      [petter, matteis, love, in, the, time, of, mon...   \n",
       "...                                                  ...   \n",
       "49995  [i, thought, this, movie, did, a, down, right,...   \n",
       "49996  [bad, plot, bad, dialogue, bad, acting, idioti...   \n",
       "49997  [i, am, a, catholic, taught, in, parochial, el...   \n",
       "49998  [im, going, to, have, to, disagree, with, the,...   \n",
       "49999  [no, one, expects, the, star, trek, movies, to...   \n",
       "\n",
       "                                 lemmatized_no_stopwords  \n",
       "0      [one, reviewer, mentioned, watching, 1, oz, ep...  \n",
       "1      [wonderful, little, production, br, br, filmin...  \n",
       "2      [thought, wonderful, way, spend, time, hot, su...  \n",
       "3      [basically, there, family, little, boy, jake, ...  \n",
       "4      [petter, matteis, love, time, money, visually,...  \n",
       "...                                                  ...  \n",
       "49995  [thought, movie, right, good, job, wasnt, crea...  \n",
       "49996  [bad, plot, bad, dialogue, bad, acting, idioti...  \n",
       "49997  [catholic, taught, parochial, elementary, scho...  \n",
       "49998  [im, going, disagree, previous, comment, side,...  \n",
       "49999  [one, expects, star, trek, movie, high, art, f...  \n",
       "\n",
       "[50000 rows x 5 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "wordnet_lemmatizer = WordNetLemmatizer()\n",
    "stop_words = nltk.corpus.stopwords.words('english')\n",
    "stop_words[0:10]\n",
    "['i', 'the', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\"]\n",
    "\n",
    "def remove_stopwords_lemmatize(text):\n",
    "    output = []\n",
    "    if type(text) is float : \n",
    "        return []\n",
    "    for i in text:\n",
    "        if i not in stop_words:\n",
    "            output.append(wordnet_lemmatizer.lemmatize(i))\n",
    "    return output\n",
    "\n",
    "dataset['lemmatized_no_stopwords'] = dataset['review_tokenied'].apply(lambda x:remove_stopwords_lemmatize(x))\n",
    "\n",
    "display(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b757fdb0",
   "metadata": {},
   "source": [
    "# Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f119d25a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>one reviewer mentioned watching 1 oz episode y...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>wonderful little production br br filming tech...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>thought wonderful way spend time hot summer we...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>basically there family little boy jake think t...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>petter matteis love time money visually stunni...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49995</th>\n",
       "      <td>thought movie right good job wasnt creative or...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49996</th>\n",
       "      <td>bad plot bad dialogue bad acting idiotic direc...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49997</th>\n",
       "      <td>catholic taught parochial elementary school nu...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49998</th>\n",
       "      <td>im going disagree previous comment side maltin...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49999</th>\n",
       "      <td>one expects star trek movie high art fan expec...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>50000 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  review sentiment\n",
       "0      one reviewer mentioned watching 1 oz episode y...  positive\n",
       "1      wonderful little production br br filming tech...  positive\n",
       "2      thought wonderful way spend time hot summer we...  positive\n",
       "3      basically there family little boy jake think t...  negative\n",
       "4      petter matteis love time money visually stunni...  positive\n",
       "...                                                  ...       ...\n",
       "49995  thought movie right good job wasnt creative or...  positive\n",
       "49996  bad plot bad dialogue bad acting idiotic direc...  negative\n",
       "49997  catholic taught parochial elementary school nu...  negative\n",
       "49998  im going disagree previous comment side maltin...  negative\n",
       "49999  one expects star trek movie high art fan expec...  negative\n",
       "\n",
       "[50000 rows x 2 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset['review'] = dataset['lemmatized_no_stopwords'].apply(lambda x:' '.join(x))\n",
    "dataset.drop('free_punc_review', inplace=True, axis=1)\n",
    "dataset.drop('review_tokenied', inplace=True, axis=1)\n",
    "dataset.drop('lemmatized_no_stopwords', inplace=True, axis=1)\n",
    "\n",
    "display(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c56e438d",
   "metadata": {},
   "source": [
    "# Data Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9a535a16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split data to positive and negative\n",
    "p_samples = dataset[dataset['sentiment'] == 'positive']\n",
    "n_samples = dataset[dataset['sentiment'] == 'negative']\n",
    "# display(p_samples)\n",
    "# display(n_samples)\n",
    "\n",
    "# split the positive class samples to (70%, 10%, 20%) for (training, validation, testing) respectively \n",
    "p_testing = p_samples.sample(frac = 0.2)\n",
    "p_validation = p_samples.drop(p_testing.index).sample(frac = 0.125)\n",
    "p_training = p_samples.drop(p_validation.index).drop(p_testing.index)\n",
    "\n",
    "# split the negative class samples to (70%, 10%, 20%) for (training, validation, testing) respectively \n",
    "n_testing = n_samples.sample(frac = 0.2)\n",
    "n_validation = n_samples.drop(n_testing.index).sample(frac = 0.125)\n",
    "n_training = n_samples.drop(n_validation.index).drop(n_testing.index)\n",
    "\n",
    "# concatenating the 70% of p-class and n-class to form the training set\n",
    "training_set = pd.concat([p_training, n_training], axis=0, ignore_index=True)\n",
    "\n",
    "# concatenating the 10% of p-class and n-class to form the validation set\n",
    "validation_set = pd.concat([p_validation, n_validation], axis=0, ignore_index=True)\n",
    "\n",
    "# concatenating the 20% of p-class and n-class to form the testing set\n",
    "testing_set = pd.concat([p_testing, n_testing], axis=0, ignore_index=True)\n",
    "\n",
    "# display(training_set)\n",
    "# display(validation_set)\n",
    "# display(testing_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86854782",
   "metadata": {},
   "source": [
    "# Classification using BERT"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c292e3f",
   "metadata": {},
   "source": [
    "### Bert Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5cd54bc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from transformers import BertTokenizer\n",
    "\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-cased')\n",
    "\n",
    "labels = {'negative': 0,\n",
    "          'positive': 1}\n",
    "\n",
    "class Dataset(torch.utils.data.Dataset):\n",
    "\n",
    "    def __init__(self, df):\n",
    "\n",
    "        self.labels = [labels[label] for label in df['sentiment']]\n",
    "        self.texts = [tokenizer(text, \n",
    "                               padding='max_length', max_length = 512, truncation=True,\n",
    "                                return_tensors=\"pt\") for text in df['review']]\n",
    "\n",
    "    def classes(self):\n",
    "        return self.labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "    def get_batch_labels(self, idx):\n",
    "        # Fetch a batch of labels\n",
    "        return np.array(self.labels[idx])\n",
    "\n",
    "    def get_batch_texts(self, idx):\n",
    "        # Fetch a batch of inputs\n",
    "        return self.texts[idx]\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "\n",
    "        batch_texts = self.get_batch_texts(idx)\n",
    "        batch_y = self.get_batch_labels(idx)\n",
    "\n",
    "        return batch_texts, batch_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "409adc2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# training_for_BERT = Dataset(training_set)\n",
    "# validation_for_BERT = Dataset(validation_set)\n",
    "testing_for_BERT = Dataset(testing_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fdc0d44",
   "metadata": {},
   "source": [
    "### Model Building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f5d04f0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "from transformers import BertModel\n",
    "\n",
    "class BertClassifier(nn.Module):\n",
    "\n",
    "    def __init__(self, dropout=0.5):\n",
    "        super(BertClassifier, self).__init__()\n",
    "        self.bert = BertModel.from_pretrained('bert-base-cased')\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.linear_layer_0 = nn.Linear(768, 512)\n",
    "        self.linear_layer_1 = nn.Linear(512, 256)\n",
    "        self.linear_layer_2 = nn.Linear(256, 128)\n",
    "        self.linear_layer_3 = nn.Linear(128, 64)\n",
    "        self.linear_layer_4 = nn.Linear(64, 1)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "        \n",
    "    def forward(self, input_id, mask):\n",
    "        _, pooled_output = self.bert(input_ids= input_id, attention_mask=mask,return_dict=False)\n",
    "        dropout_output = self.dropout(pooled_output)\n",
    "        relu_0 = self.relu(self.linear_layer_0(dropout_output))\n",
    "        relu_1 = self.relu(self.linear_layer_1(relu_0))\n",
    "        relu_2 = self.relu(self.linear_layer_2(relu_1))\n",
    "        relu_3 = self.relu(self.linear_layer_3(relu_2))\n",
    "        final_output = self.relu(self.linear_layer_4(relu_3))\n",
    "\n",
    "        return final_output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26ff550a",
   "metadata": {},
   "source": [
    "### Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "10d3ca5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.optim import Adam\n",
    "from tqdm import tqdm\n",
    "\n",
    "epoch_no = []\n",
    "training_acc = []\n",
    "validation_acc = []\n",
    "\n",
    "def train(model, train_data, val_data, learning_rate, epochs):\n",
    "    global epoch_no, training_acc, validation_acc\n",
    "    epoch_no = []\n",
    "    training_acc = []\n",
    "    validation_acc = []\n",
    "    \n",
    "    train, val = Dataset(train_data), Dataset(val_data)\n",
    "\n",
    "    # load data to main memory\n",
    "    train_dataloader = torch.utils.data.DataLoader(train, batch_size=8, shuffle=True)\n",
    "    val_dataloader = torch.utils.data.DataLoader(val, batch_size=8)\n",
    "\n",
    "    # load data to GPU if possible (if cuda exists)\n",
    "    use_cuda = torch.cuda.is_available()\n",
    "    device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "\n",
    "    # define criteria (loss function) & used optimizer\n",
    "    criterion = nn.BCELoss()\n",
    "    optimizer = Adam(model.parameters(), lr= learning_rate)\n",
    "    \n",
    "    if use_cuda:\n",
    "        print('cuda exists')\n",
    "        model = model.cuda()\n",
    "        criterion = criterion.cuda()\n",
    "    else:\n",
    "        print('No cuda')\n",
    "        \n",
    "    for epoch_num in range(epochs):\n",
    "        epoch_no.append(epoch_num + 1)\n",
    "        total_acc_train = 0\n",
    "        total_loss_train = 0\n",
    "        \n",
    "        for train_input, train_label in tqdm(train_dataloader):\n",
    "            train_label = train_label.reshape((8,1)).float().to(device)\n",
    "            print(train_label) ###################\n",
    "            mask = train_input['attention_mask'].to(device)\n",
    "            input_id = train_input['input_ids'].squeeze(1).to(device)\n",
    "\n",
    "            output = model(input_id, mask)\n",
    "            print(output) ###################\n",
    "\n",
    "            batch_loss = criterion(output, train_label)\n",
    "            total_loss_train += batch_loss.item()\n",
    "\n",
    "            acc = (output.argmax(dim=1) == train_label).sum().item()\n",
    "            total_acc_train += acc\n",
    "\n",
    "            model.zero_grad()\n",
    "            batch_loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        training_acc.append(total_acc_train / len(train_data))\n",
    "        \n",
    "        total_acc_val = 0\n",
    "        total_loss_val = 0\n",
    "        with torch.no_grad():\n",
    "\n",
    "            for val_input, val_label in val_dataloader:\n",
    "\n",
    "                val_label = val_label.to(device)\n",
    "                mask = val_input['attention_mask'].to(device)\n",
    "                input_id = val_input['input_ids'].squeeze(1).to(device)\n",
    "\n",
    "                output = model(input_id, mask).float()\n",
    "\n",
    "                batch_loss = criterion(output, val_label)\n",
    "                total_loss_val += batch_loss.item()\n",
    "\n",
    "                acc = (output.argmax(dim=1) == val_label).sum().item()\n",
    "                total_acc_val += acc\n",
    "\n",
    "            validation_acc.append(total_acc_val / len(val_data))\n",
    "#         print(\n",
    "#             f'Epochs: {epoch_num + 1} | Train Loss: {total_loss_train / len(train_data): .3f} \\\n",
    "#             | Train Accuracy: {total_acc_train / len(train_data): .3f} \\\n",
    "#             | Val Loss: {total_loss_val / len(val_data): .3f} \\\n",
    "#             | Val Accuracy: {total_acc_val / len(val_data): .3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1358dc94",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-cased were not used when initializing BertModel: ['cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "  0%|                                                                                         | 0/4375 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No cuda\n",
      "tensor([[1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.]])\n",
      "tensor([[0.0157],\n",
      "        [0.0337],\n",
      "        [0.0421],\n",
      "        [0.0236],\n",
      "        [0.0419],\n",
      "        [0.0183],\n",
      "        [0.0290],\n",
      "        [0.0267]], grad_fn=<ReluBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                                            | 1/4375 [02:45<201:04:54, 165.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.]])\n",
      "tensor([[0.0253],\n",
      "        [0.0317],\n",
      "        [0.0420],\n",
      "        [0.0206],\n",
      "        [0.0501],\n",
      "        [0.0090],\n",
      "        [0.0205],\n",
      "        [0.0449]], grad_fn=<ReluBackward0>)\n"
     ]
    }
   ],
   "source": [
    "no_of_epochs = 5\n",
    "model = BertClassifier()\n",
    "learning_rate = 1e-6\n",
    "              \n",
    "train(model, training_set, validation_set, learning_rate, no_of_epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c743375",
   "metadata": {},
   "source": [
    "### Plotting Accuracy vs No of Epochs in Training & Validation Sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd8ea790",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(epoch_no, training_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c93fb9dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(epoch_no, validation_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3c5802f",
   "metadata": {},
   "source": [
    "### Plotting Acuraccy vs Learning Rate in Validation Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86578e3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "no_of_epochs = 5 # to be modified\n",
    "model_ = BertClassifier()\n",
    "LRs = [1e-6, 1e-5] # to be modified\n",
    "accuracy = []             \n",
    "for i in LRs:\n",
    "    train(model, training_set, validation_set, i, no_of_epochs)\n",
    "    accuracy.append(validation_acc[-1])\n",
    "plt.plot(LRs, accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e47703d7",
   "metadata": {},
   "source": [
    "### Plotting Accuracy with\\out Text Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fc2e1a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, test_data):\n",
    "\n",
    "    test = Dataset(test_data)\n",
    "\n",
    "    test_dataloader = torch.utils.data.DataLoader(test, batch_size=2)\n",
    "\n",
    "    use_cuda = torch.cuda.is_available()\n",
    "    device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "\n",
    "    if use_cuda:\n",
    "        model = model.cuda()\n",
    "\n",
    "    total_acc_test = 0\n",
    "    with torch.no_grad():\n",
    "        for test_input, test_label in test_dataloader:\n",
    "          test_label = test_label.to(device)\n",
    "          mask = test_input['attention_mask'].to(device)\n",
    "          input_id = test_input['input_ids'].squeeze(1).to(device)\n",
    "\n",
    "          output = model(input_id, mask)\n",
    "\n",
    "          acc = (output.argmax(dim=1) == test_label).sum().item()\n",
    "          total_acc_test += acc\n",
    "    \n",
    "#     print(f'Test Accuracy: {total_acc_test / len(test_data): .3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "388efe06",
   "metadata": {},
   "outputs": [],
   "source": [
    "def conf_matrix_calculations(actual, predicted):\n",
    "    TP = TN = FP = FN = 0\n",
    "    training_dataset_size = 10000\n",
    "    for i in range (training_dataset_size):\n",
    "        if actual[i] == 'positive' and predicted[i] == 'positive':\n",
    "            TP += 1\n",
    "        elif actual[i] == 'positive' and predicted[i] == 'negative':\n",
    "            FN += 1\n",
    "        elif actual[i] == 'negative' and predicted[i] == 'negative':\n",
    "            TN += 1\n",
    "        elif actual[i] == 'negative' and predicted[i] == 'positive':\n",
    "            FP += 1\n",
    "    print('--- Confusion Matrix ---')\n",
    "    print('TP: ', TP, '\\tFP: ', FP)\n",
    "    print('FN: ', FN, '\\tTN: ', TN)\n",
    "    print('Accuracy = ', accuracy(TP, FP, FN, TN))\n",
    "    p = precision(TP, FP)\n",
    "    print('Precision = ', p)\n",
    "    r = recall(TP, FN)\n",
    "    print('Recall = ', r)\n",
    "    print('F-score = ', f_score(p, r))\n",
    "    \n",
    "def accuracy(TP, FP, FN, TN):\n",
    "    return (TP + TN) / (TP + FP + FN + TN)\n",
    "\n",
    "def precision(TP, FP):\n",
    "    return (TP) / (TP + FP)\n",
    "\n",
    "def recall(TP, FN):\n",
    "    return (TP) / (TP + FN)\n",
    "\n",
    "def f_score(p, r):\n",
    "    return (2 * p * r) / (p + r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dd10fb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate(model, df_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
